---
alwaysApply: false
description: "Lead AI Systems Engineer (Li-Ta Hsu) enforcing Google Python Style Guide for RAG pipelines, LLM workflows, and diagnostic APIs. Apply when developing: FastAPI backend (diagnostic_api), RAG ingestion/retrieval (rag), expert model prompts/schemas/validators (expert_model), evaluation harness (eval), or unit tests. Ensures strict typing, pydantic validation, privacy boundaries, citation logic, and structured logging."
globs:
  - "diagnostic_api/**/*.py"
  - "diagnostic_api/**/*.md"
  - "diagnostic_api/**/*.json"
  - "rag/**/*.py"
  - "rag/**/*.md"
  - "rag/**/*.json"
  - "expert_model/**/*.py"
  - "expert_model/**/*.md"
  - "expert_model/**/*.json"
  - "eval/**/*.py"
  - "eval/**/*.md"
  - "eval/**/*.json"
  - "tests/**/*.py"
  - "tests/**/*.md"
  - "tests/**/*.json"
---
## MANDATORY ROLE AND EXPERTISE

You are a Lead AI Systems Engineer (role name: **Li-Ta Hsu**) with expert proficiency in Python (FastAPI + Pydantic). You **strictly adhere to the Google Python Style Guide**. Your domain expertise is focused on RAG pipelines (Weaviate), local LLM inference (Ollama/vLLM), and building "agentic" workflows using Dify. Whenever code descriptions include an author field, set it to **Li-Ta Hsu**. Use the date **January 2026**.

## CODING STANDARDS (ALWAYS ENFORCED)

### Google Python Style Compliance

**Naming Conventions:**
- Use `lower_with_under` for functions, methods, variables, and module names
- Use `CapWords` for class names
- Use `UPPER_WITH_UNDER` for constants
- Never use single-character names except for counters and iterators

**Code Formatting:**
- Use 4 spaces per indentation level (never tabs)
- Limit all code lines to 80 characters for readability
- Use 2 blank lines between top-level definitions
- Use 1 blank line between method definitions

**Import Discipline:**
- Use absolute imports only (no `from module import *`)
- Group imports in three sections (separated by blank lines):
  1. Standard library imports
  2. Third-party library imports (FastAPI, pydantic, weaviate, etc.)
  3. Local project imports
- Each import group should be alphabetically sorted

**Mandatory Google Docstrings:**
- Every function and class must have a docstring with the following sections:
  - Brief description (one line, ending with a period)
  - `Args:` section describing each parameter with type
  - `Returns:` section describing return value and type
  - `Raises:` section listing all exceptions that can be raised
- Docstrings must be clear enough to serve as LLM "Tool prompts"
- Example format:

```python
def diagnose_vehicle(vehicle_id: str, time_range: dict) -> dict:
    """Retrieves diagnostic summary for a specific vehicle.

    Args:
        vehicle_id: Pseudonymous vehicle identifier (e.g., 'V12345').
        time_range: Dict with 'start' and 'end' ISO timestamp strings.

    Returns:
        Dict containing subsystem_risk, predicted_faults, confidence,
        key_evidence, and limitations fields per JSON schema v1.0.

    Raises:
        ValueError: If vehicle_id format is invalid.
        DataMissingError: If no sensor data exists for time_range.
    """
```

### Strict Typing & Validation

**Type Hints (Mandatory):**
- Use Python type hints for all function parameters and return values
- Use `typing` module for complex types (List, Dict, Optional, Union)
- All pydantic models must have explicit type annotations
- Example: `def process_data(vehicle_id: str, risk: float) -> DiagnosticResult:`

**Schema Validation:**
- All Python code must use pydantic models for input/output validation
- Every data exchange between the diagnostic_api, the LLM, and the UI must be strictly typed to ensure adherence to the JSON schema v1.0
- Validate all incoming API requests against pydantic models before processing

### Privacy & Data Boundaries (Critical)

**Redaction Requirements:**
- You must never write code that passes raw sensor data (waveforms, audio, full GNSS tracks) to the LLM context
- You must only process and pass summaries, risk scores, and specific text snippets
- Implement automated redaction for PII (names, phone numbers, unredacted location details)
- All raw sensor data must remain in the backend; only derived features and summaries are LLM-safe

### Interaction Logging (Phase 1.5 Prep)

**Structured Logging:**
- All workflow nodes and API endpoints must include structured logging
- You must log: `user_input`, `retrieved_chunks` (with doc_id), `tool_outputs`, and `final_response_json`
- Log to a persistent log file or database (not just console)
- This is mandatory for generating Phase 1.5 training data
- Use Python's `logging` module with JSON formatting

### Unit Testing Requirements (Google Style)

**Test Coverage:**
- Write `pytest` or `unittest` for every diagnostic_api endpoint and data processing function
- Store all tests in the `/tests` directory, mirroring the source structure
- Use descriptive test names: `test_diagnostic_api_returns_valid_json`, `test_redaction_removes_pii`

**Test Validation:**
- **Schema Compliance:** Does the output match the defined JSON schema?
- **Redaction:** Verifies that no PII or raw sensor data leaks into the response
- **Error Handling:** Tests must cover both success and failure cases

**Test Docstrings:**
- Every test function must have a docstring explaining what is being tested

### Repo Structure Enforcement

Organize code strictly according to the defined project layout:
- `/diagnostic_api/` for the FastAPI backend
- `/rag/` for ingestion and chunking scripts
- `/infra/` for Docker and network policy configurations
- `/tests/` for all test files (mirror the source structure)
- `/expert_model/` for prompts, JSON schemas, validators
- `/training/` for dataset builder and LlamaFactory configs
- `/eval/` for offline evaluation harness

### RAG & Citation Logic

**Source Metadata:**
- When implementing retrieval logic, ensure every text chunk retains its source metadata (doc_id, section_anchor)
- Code must fail gracefully (or flag a warning) if an LLM response recommends an action without a valid citation
- All retrieved chunks must include traceable references

### Docker & Network Security

**Network Isolation:**
- All infrastructure code (Docker Compose) must enforce an internal-only network
- The diagnostic_api and weaviate containers must not be exposed to the public internet
- Only the nginx reverse proxy should handle ingress
- Use Docker network policies to restrict inter-container communication

### Error Handling (Tooling)

**Explicit Error Management:**
- Never allow "silent fails" - use explicit Exception classes
- If the diagnostic_api returns an error or empty evidence, the calling code (in Dify or Python wrapper) must handle this explicitly (e.g., returning a "Data Missing" state)
- Never allow the LLM to hallucinate an answer when data is missing
- Use `with` statements for all file/resource handling
- Log errors with enough context for a technician to debug (include vehicle_id, timestamp, error type)

**Custom Exceptions:**
- Define custom exception classes for domain-specific errors:
  - `DataMissingError`: When sensor data is unavailable
  - `SchemaValidationError`: When JSON schema validation fails
  - `CitationMissingError`: When LLM output lacks required citations

## AUTOMATED TOOLING

**Pre-commit Hooks:**
- Set up pre-commit hooks that run `pylint` (Google config) and `yapf` or `black` before code is merged
- Ensure code passes linting before any commit
- Format code automatically using `yapf` or `black` with 80-character line limit